{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/NLP_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhggiMFW0kiQ",
        "outputId": "0bc2664c-dcdd-45e9-e614-e8160df50df4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/NLP_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  train_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/train_filtered_True_False.csv'\n",
        "  valid_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/valid_filtered_True_False.csv'\n",
        "  test_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/test_filtered_True_False.csv'"
      ],
      "metadata": {
        "id": "61p16nB70rlk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMeyYYqufSXg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkXiBUeT0hVo",
        "outputId": "318cbddc-c850-45b8-a39a-9fa9a5b00808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pybloom_live in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: bitarray>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pybloom_live) (2.8.3)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pybloom_live) (3.4.1)\n",
            "Unique Label values: {'TRUE', 'FALSE'}\n",
            "Accuracy on validation set: 45.71%\n",
            "Unique Label values: {'TRUE', 'FALSE'}\n",
            "Accuracy on test set: 60.94%\n"
          ]
        }
      ],
      "source": [
        "!pip install pybloom_live\n",
        "import csv\n",
        "from pybloom_live import BloomFilter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Load labels and text from a CSV file.\n",
        "    \"\"\"\n",
        "    labels, texts = [], []\n",
        "    unique_labels = set()  # To store unique label values\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            label_str = row['Label'].upper()  # Convert to uppercase for case-insensitive check\n",
        "            if label_str not in ('TRUE', 'FALSE'):\n",
        "                print(f\"Warning: Unexpected label value '{label_str}'. Skipping this row.\")\n",
        "                continue\n",
        "\n",
        "            unique_labels.add(label_str)\n",
        "            label = 1 if label_str == 'TRUE' else 0  # Convert to binary (1 for TRUE, 0 for FALSE)\n",
        "            labels.append(label)\n",
        "            texts.append(row['Text'])\n",
        "\n",
        "    # Print unique label values\n",
        "    print(\"Unique Label values:\", unique_labels)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "def build_bloom_filter(training_texts, capacity, error_rate):\n",
        "    \"\"\"\n",
        "    Build a Bloom filter using PyBloom on the training texts.\n",
        "    \"\"\"\n",
        "    bloom_filter = BloomFilter(capacity, error_rate)\n",
        "    for text in training_texts:\n",
        "        bloom_filter.add(text)\n",
        "    return bloom_filter\n",
        "\n",
        "def apply_bloom_filter(bloom_filter, dataset_texts):\n",
        "    \"\"\"\n",
        "    Apply the Bloom filter to a dataset and return the predicted labels.\n",
        "    \"\"\"\n",
        "    predictions = [1 if text in bloom_filter else 0 for text in dataset_texts]\n",
        "    return predictions\n",
        "\n",
        "def main():\n",
        "    # Paths to the CSV files for train and test datasets\n",
        "    train_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/train_filtered_True_False.csv'\n",
        "    valid_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/valid_filtered_True_False.csv'\n",
        "    test_csv_path = '/content/drive/MyDrive/NLP_Project/liar_dataset/test_filtered_True_False.csv'\n",
        "\n",
        "    # Load the entire training dataset\n",
        "    train_texts, train_labels = load_dataset(train_csv_path)\n",
        "\n",
        "    # Split the training dataset into training and validation sets\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        train_texts, train_labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Choose appropriate parameters for Bloom filter\n",
        "    capacity = 1000\n",
        "    error_rate = 0.001\n",
        "\n",
        "    # Build Bloom filter on the training set\n",
        "    bloom_filter = build_bloom_filter(X_train, capacity, error_rate)\n",
        "\n",
        "    # Apply Bloom filter to validation set\n",
        "    valid_predictions = apply_bloom_filter(bloom_filter, X_valid)\n",
        "\n",
        "    # Evaluate accuracy on the validation set\n",
        "    accuracy_on_valid = accuracy_score(y_valid, valid_predictions)\n",
        "    print(f\"Accuracy on validation set: {accuracy_on_valid * 100:.2f}%\")\n",
        "\n",
        "    # Apply Bloom filter to test set\n",
        "    test_texts, test_labels = load_dataset(test_csv_path)\n",
        "    test_predictions = apply_bloom_filter(bloom_filter, test_texts)\n",
        "\n",
        "    # Evaluate accuracy on the test set\n",
        "    accuracy_on_test = accuracy_score(test_labels, test_predictions)\n",
        "    print(f\"Accuracy on test set: {accuracy_on_test * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}